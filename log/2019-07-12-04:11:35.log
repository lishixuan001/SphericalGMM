2019-07-12 04:11:35 INFO     Loading Data
2019-07-12 04:11:40 INFO     Model Setting Up
2019-07-12 04:11:47 INFO     train_dir : [../dataset/mnist/train]
2019-07-12 04:11:47 INFO     test_dir : [../dataset/mnist/test]
2019-07-12 04:11:47 INFO     save_dir : [./save]
2019-07-12 04:11:47 INFO     gpu : [5]
2019-07-12 04:11:47 INFO     num_epochs : [300]
2019-07-12 04:11:47 INFO     batch_size : [256]
2019-07-12 04:11:47 INFO     num_points : [512]
2019-07-12 04:11:47 INFO     visualize : [False]
2019-07-12 04:11:47 INFO     log_interval : [1000]
2019-07-12 04:11:47 INFO     save_interval : [20]
2019-07-12 04:11:47 INFO     baselr : [5e-05]
2019-07-12 04:11:47 INFO     density_radius : [0.2]
2019-07-12 04:11:47 INFO     num_grids : [3]
2019-07-12 04:11:47 INFO     base_radius : [1]
2019-07-12 04:11:47 INFO     static_sigma : [0.05]
2019-07-12 04:11:47 INFO     use_static_sigma : [False]
2019-07-12 04:11:47 INFO     use_weights : [False]
2019-07-12 04:11:47 INFO     sigma_layer_diff : [True]
2019-07-12 04:11:47 INFO     feature_out1 : [8]
2019-07-12 04:11:47 INFO     feature_out2 : [16]
2019-07-12 04:11:47 INFO     feature_out3 : [32]
2019-07-12 04:11:47 INFO     feature_out4 : [64]
2019-07-12 04:11:47 INFO     feature_out5 : [128]
2019-07-12 04:11:47 INFO     num_classes : [10]
2019-07-12 04:11:47 INFO     num_so3_layers : [3]
2019-07-12 04:11:47 INFO     bandwidth_0 : [10]
2019-07-12 04:11:47 INFO     bandwidth_out1 : [10]
2019-07-12 04:11:47 INFO     bandwidth_out2 : [8]
2019-07-12 04:11:47 INFO     bandwidth_out3 : [6]
2019-07-12 04:11:47 INFO     bandwidth_out4 : [4]
2019-07-12 04:11:47 INFO     bandwidth_out5 : [2]
2019-07-12 04:11:47 INFO     resume_training : [0]
2019-07-12 04:11:47 INFO     Start Training
2019-07-12 04:11:54 INFO     Batch: [0/235] Epoch: [0] Loss: [2.29758358001709]
2019-07-12 04:11:54 INFO     Batch: [1/235] Epoch: [0] Loss: [2.3037304878234863]
2019-07-12 04:11:55 INFO     Batch: [2/235] Epoch: [0] Loss: [2.3063042163848877]
2019-07-12 04:11:55 INFO     Batch: [3/235] Epoch: [0] Loss: [2.3046956062316895]
2019-07-12 04:11:55 INFO     Batch: [4/235] Epoch: [0] Loss: [2.3043022632598875]
2019-07-12 04:11:56 INFO     Batch: [5/235] Epoch: [0] Loss: [2.302782972653707]
2019-07-12 04:11:56 INFO     Batch: [6/235] Epoch: [0] Loss: [2.3020198345184326]
2019-07-12 04:11:56 INFO     Batch: [7/235] Epoch: [0] Loss: [2.3013429045677185]
2019-07-12 04:11:57 INFO     Batch: [8/235] Epoch: [0] Loss: [2.2990936173333063]
2019-07-12 04:11:57 INFO     Batch: [9/235] Epoch: [0] Loss: [2.2976794242858887]
2019-07-12 04:11:57 INFO     Batch: [10/235] Epoch: [0] Loss: [2.29704271663319]
2019-07-12 04:11:58 INFO     Batch: [11/235] Epoch: [0] Loss: [2.2959206899007163]
2019-07-12 04:11:58 INFO     Batch: [12/235] Epoch: [0] Loss: [2.2946641078362098]
2019-07-12 04:11:58 INFO     Batch: [13/235] Epoch: [0] Loss: [2.2936815874917165]
2019-07-12 04:11:59 INFO     Batch: [14/235] Epoch: [0] Loss: [2.291914399464925]
2019-07-12 04:11:59 INFO     Batch: [15/235] Epoch: [0] Loss: [2.291109636425972]
2019-07-12 04:11:59 INFO     Batch: [16/235] Epoch: [0] Loss: [2.290472212959738]
2019-07-12 04:12:00 INFO     Batch: [17/235] Epoch: [0] Loss: [2.289871189329359]
2019-07-12 04:12:00 INFO     Batch: [18/235] Epoch: [0] Loss: [2.288995542024311]
2019-07-12 04:12:00 INFO     Batch: [19/235] Epoch: [0] Loss: [2.287656271457672]
2019-07-12 04:12:00 INFO     Batch: [20/235] Epoch: [0] Loss: [2.2866073108854748]
2019-07-12 04:12:01 INFO     Batch: [21/235] Epoch: [0] Loss: [2.2856981429186733]
2019-07-12 04:12:01 INFO     Batch: [22/235] Epoch: [0] Loss: [2.2844038009643555]
2019-07-12 04:12:01 INFO     Batch: [23/235] Epoch: [0] Loss: [2.2827332516511283]
2019-07-12 04:12:02 INFO     Batch: [24/235] Epoch: [0] Loss: [2.281424741744995]
2019-07-12 04:12:02 INFO     Batch: [25/235] Epoch: [0] Loss: [2.2801420780328603]
2019-07-12 04:12:02 INFO     Batch: [26/235] Epoch: [0] Loss: [2.2794086226710566]
2019-07-12 04:12:03 INFO     Batch: [27/235] Epoch: [0] Loss: [2.278085001877376]
2019-07-12 04:12:03 INFO     Batch: [28/235] Epoch: [0] Loss: [2.277403338202115]
2019-07-12 04:12:03 INFO     Batch: [29/235] Epoch: [0] Loss: [2.276131598154704]
2019-07-12 04:12:04 INFO     Batch: [30/235] Epoch: [0] Loss: [2.2752082424779094]
2019-07-12 04:12:04 INFO     Batch: [31/235] Epoch: [0] Loss: [2.274357557296753]
2019-07-12 04:12:04 INFO     Batch: [32/235] Epoch: [0] Loss: [2.2736322446302935]
2019-07-12 04:12:05 INFO     Batch: [33/235] Epoch: [0] Loss: [2.2728423090542065]
2019-07-12 04:12:05 INFO     Batch: [34/235] Epoch: [0] Loss: [2.271459027699062]
2019-07-12 04:12:05 INFO     Batch: [35/235] Epoch: [0] Loss: [2.2705477476119995]
2019-07-12 04:12:06 INFO     Batch: [36/235] Epoch: [0] Loss: [2.2694156298766264]
2019-07-12 04:12:06 INFO     Batch: [37/235] Epoch: [0] Loss: [2.268216453100506]
2019-07-12 04:12:06 INFO     Batch: [38/235] Epoch: [0] Loss: [2.267064339075333]
2019-07-12 04:12:06 INFO     Batch: [39/235] Epoch: [0] Loss: [2.2661134362220765]
2019-07-12 04:12:07 INFO     Batch: [40/235] Epoch: [0] Loss: [2.2650959608031482]
2019-07-12 04:12:07 INFO     Batch: [41/235] Epoch: [0] Loss: [2.263929775782994]
2019-07-12 04:12:07 INFO     Batch: [42/235] Epoch: [0] Loss: [2.262999312822209]
2019-07-12 04:12:08 INFO     Batch: [43/235] Epoch: [0] Loss: [2.2621169686317444]
2019-07-12 04:12:08 INFO     Batch: [44/235] Epoch: [0] Loss: [2.2613304720984564]
2019-07-12 04:12:08 INFO     Batch: [45/235] Epoch: [0] Loss: [2.2602149921914805]
2019-07-12 04:12:09 INFO     Batch: [46/235] Epoch: [0] Loss: [2.259087029923784]
2019-07-12 04:12:09 INFO     Batch: [47/235] Epoch: [0] Loss: [2.258351986606916]
2019-07-12 04:12:09 INFO     Batch: [48/235] Epoch: [0] Loss: [2.2572656942873586]
2019-07-12 04:12:10 INFO     Batch: [49/235] Epoch: [0] Loss: [2.2560951328277588]
2019-07-12 04:12:10 INFO     Batch: [50/235] Epoch: [0] Loss: [2.2547782402412566]
2019-07-12 04:12:10 INFO     Batch: [51/235] Epoch: [0] Loss: [2.253792712321648]
2019-07-12 04:12:11 INFO     Batch: [52/235] Epoch: [0] Loss: [2.2525100483084626]
2019-07-12 04:12:11 INFO     Batch: [53/235] Epoch: [0] Loss: [2.2512973458678633]
2019-07-12 04:12:11 INFO     Batch: [54/235] Epoch: [0] Loss: [2.250181713971225]
2019-07-12 04:12:12 INFO     Batch: [55/235] Epoch: [0] Loss: [2.249294114964349]
2019-07-12 04:12:12 INFO     Batch: [56/235] Epoch: [0] Loss: [2.2481724170216344]
2019-07-12 04:12:12 INFO     Batch: [57/235] Epoch: [0] Loss: [2.2471326466264396]
2019-07-12 04:12:13 INFO     Batch: [58/235] Epoch: [0] Loss: [2.2462870468527583]
2019-07-12 04:12:13 INFO     Batch: [59/235] Epoch: [0] Loss: [2.245150546232859]
2019-07-12 04:12:13 INFO     Batch: [60/235] Epoch: [0] Loss: [2.2441023568638037]
2019-07-12 04:12:14 INFO     Batch: [61/235] Epoch: [0] Loss: [2.242981041631391]
2019-07-12 04:12:14 INFO     Batch: [62/235] Epoch: [0] Loss: [2.2417958993760365]
2019-07-12 04:12:14 INFO     Batch: [63/235] Epoch: [0] Loss: [2.240507323294878]
2019-07-12 04:12:14 INFO     Batch: [64/235] Epoch: [0] Loss: [2.239542062465961]
2019-07-12 04:12:15 INFO     Batch: [65/235] Epoch: [0] Loss: [2.238606507127935]
2019-07-12 04:12:15 INFO     Batch: [66/235] Epoch: [0] Loss: [2.2376361604946764]
2019-07-12 04:12:15 INFO     Batch: [67/235] Epoch: [0] Loss: [2.2361323763342464]
2019-07-12 04:12:16 INFO     Batch: [68/235] Epoch: [0] Loss: [2.235008098077083]
2019-07-12 04:12:16 INFO     Batch: [69/235] Epoch: [0] Loss: [2.2336276939937045]
2019-07-12 04:12:16 INFO     Batch: [70/235] Epoch: [0] Loss: [2.2330609274582125]
2019-07-12 04:12:17 INFO     Batch: [71/235] Epoch: [0] Loss: [2.2320048246118755]
2019-07-12 04:12:17 INFO     Batch: [72/235] Epoch: [0] Loss: [2.230877010789636]
2019-07-12 04:12:17 INFO     Batch: [73/235] Epoch: [0] Loss: [2.229957541903934]
2019-07-12 04:12:18 INFO     Batch: [74/235] Epoch: [0] Loss: [2.2286511262257895]
2019-07-12 04:12:18 INFO     Batch: [75/235] Epoch: [0] Loss: [2.2274850042242753]
2019-07-12 04:12:18 INFO     Batch: [76/235] Epoch: [0] Loss: [2.22638699915502]
2019-07-12 04:12:19 INFO     Batch: [77/235] Epoch: [0] Loss: [2.225183040667803]
2019-07-12 04:12:19 INFO     Batch: [78/235] Epoch: [0] Loss: [2.2235936877093736]
2019-07-12 04:12:19 INFO     Batch: [79/235] Epoch: [0] Loss: [2.2227189034223556]
2019-07-12 04:12:20 INFO     Batch: [80/235] Epoch: [0] Loss: [2.2219026118148992]
2019-07-12 04:12:20 INFO     Batch: [81/235] Epoch: [0] Loss: [2.2207032296715714]
2019-07-12 04:12:20 INFO     Batch: [82/235] Epoch: [0] Loss: [2.219785133040095]
2019-07-12 04:12:21 INFO     Batch: [83/235] Epoch: [0] Loss: [2.2187553076517013]
2019-07-12 04:12:21 INFO     Batch: [84/235] Epoch: [0] Loss: [2.2174572720247157]
