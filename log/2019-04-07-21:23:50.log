2019-04-07 21:23:50 INFO     Loading Data
2019-04-07 21:23:51 INFO     Model Setting Up
2019-04-07 21:23:59 INFO     train_dir : [../mnist/train]
2019-04-07 21:23:59 INFO     test_dir : [../mnist/test]
2019-04-07 21:23:59 INFO     save_dir : [./save]
2019-04-07 21:23:59 INFO     num_epochs : [250]
2019-04-07 21:23:59 INFO     batch_size : [500]
2019-04-07 21:23:59 INFO     num_points : [512]
2019-04-07 21:23:59 INFO     sigma : [0.05]
2019-04-07 21:23:59 INFO     log_interval : [1000]
2019-04-07 21:23:59 INFO     save_interval : [50]
2019-04-07 21:23:59 INFO     baselr : [5e-05]
2019-04-07 21:23:59 INFO     density_radius : [0.2]
2019-04-07 21:23:59 INFO     feature_out1 : [8]
2019-04-07 21:23:59 INFO     feature_out2 : [16]
2019-04-07 21:23:59 INFO     feature_out3 : [32]
2019-04-07 21:23:59 INFO     feature_out4 : [64]
2019-04-07 21:23:59 INFO     feature_out5 : [128]
2019-04-07 21:23:59 INFO     num_classes : [10]
2019-04-07 21:23:59 INFO     bandwidth_0 : [10]
2019-04-07 21:23:59 INFO     bandwidth_out1 : [10]
2019-04-07 21:23:59 INFO     bandwidth_out2 : [8]
2019-04-07 21:23:59 INFO     bandwidth_out3 : [6]
2019-04-07 21:23:59 INFO     bandwidth_out4 : [4]
2019-04-07 21:23:59 INFO     bandwidth_out5 : [2]
2019-04-07 21:23:59 INFO     resume_training : [0]
2019-04-07 21:23:59 INFO     Start Training
2019-04-07 21:23:59 INFO     Saved model checkpoints into ./save/2019-04-07_21-23-59-model.ckpt...
2019-04-07 21:24:04 INFO     Batch: [0/120] Epoch: [0] Loss: [2.292797327041626]
2019-04-07 21:24:04 INFO     Batch: [1/120] Epoch: [0] Loss: [2.3012022972106934]
2019-04-07 21:24:04 INFO     Batch: [2/120] Epoch: [0] Loss: [2.3043864568074546]
2019-04-07 21:24:04 INFO     Batch: [3/120] Epoch: [0] Loss: [2.3028979897499084]
2019-04-07 21:24:05 INFO     Batch: [4/120] Epoch: [0] Loss: [2.3023030757904053]
2019-04-07 21:24:05 INFO     Batch: [5/120] Epoch: [0] Loss: [2.3030160665512085]
2019-04-07 21:24:05 INFO     Batch: [6/120] Epoch: [0] Loss: [2.30177218573434]
2019-04-07 21:24:05 INFO     Batch: [7/120] Epoch: [0] Loss: [2.3015878200531006]
2019-04-07 21:24:05 INFO     Batch: [8/120] Epoch: [0] Loss: [2.301120334201389]
2019-04-07 21:24:06 INFO     Batch: [9/120] Epoch: [0] Loss: [2.3010114192962647]
2019-04-07 21:24:06 INFO     Batch: [10/120] Epoch: [0] Loss: [2.3002136837352407]
2019-04-07 21:24:06 INFO     Batch: [11/120] Epoch: [0] Loss: [2.3001352151234946]
2019-04-07 21:24:06 INFO     Batch: [12/120] Epoch: [0] Loss: [2.2994562845963697]
2019-04-07 21:24:06 INFO     Batch: [13/120] Epoch: [0] Loss: [2.299501691545759]
2019-04-07 21:24:07 INFO     Batch: [14/120] Epoch: [0] Loss: [2.299239714940389]
2019-04-07 21:24:07 INFO     Batch: [15/120] Epoch: [0] Loss: [2.2988749593496323]
2019-04-07 21:24:07 INFO     Batch: [16/120] Epoch: [0] Loss: [2.2984133888693417]
2019-04-07 21:24:07 INFO     Batch: [17/120] Epoch: [0] Loss: [2.298025051752726]
2019-04-07 21:24:07 INFO     Batch: [18/120] Epoch: [0] Loss: [2.2974908853832043]
2019-04-07 21:24:07 INFO     Batch: [19/120] Epoch: [0] Loss: [2.297015678882599]
2019-04-07 21:24:08 INFO     Batch: [20/120] Epoch: [0] Loss: [2.2964965048290433]
2019-04-07 21:24:08 INFO     Batch: [21/120] Epoch: [0] Loss: [2.2957812439311636]
2019-04-07 21:24:08 INFO     Batch: [22/120] Epoch: [0] Loss: [2.2957733195760976]
2019-04-07 21:24:08 INFO     Batch: [23/120] Epoch: [0] Loss: [2.2952573597431183]
2019-04-07 21:24:08 INFO     Batch: [24/120] Epoch: [0] Loss: [2.2948144817352296]
2019-04-07 21:24:09 INFO     Batch: [25/120] Epoch: [0] Loss: [2.2944776736772976]
2019-04-07 21:24:09 INFO     Batch: [26/120] Epoch: [0] Loss: [2.294094271130032]
2019-04-07 21:24:09 INFO     Batch: [27/120] Epoch: [0] Loss: [2.2933706641197205]
2019-04-07 21:24:09 INFO     Batch: [28/120] Epoch: [0] Loss: [2.2928669781520448]
